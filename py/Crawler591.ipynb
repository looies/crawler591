{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import datetime\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "from glob import glob\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "from Crawler import Crawler\n",
    "from Header import header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(r\"D:\\591\\property\\a.property\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = config['DEFAULT']['log_dir']\n",
    "save_dir = config['DEFAULT']['save_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s [%(name)s] [%(levelname)s]: %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    # stream=sys.stdout\n",
    "                    handlers=[logging.FileHandler(log_dir + '\\\\' + '{0}_crawler591.log'.format(datetime.datetime.strftime(datetime.datetime.now(), \"%Y%m%d_%H%M%S\")), 'w', 'utf-8'), ]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Crawler591:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.crawler = Crawler()\n",
    "        self.logger = logging.getLogger('Crawler591')\n",
    "    \n",
    "    def get_details(self, save_dir):\n",
    "        # 先取得已經下載的清單\n",
    "        all_files = glob(save_dir + '\\\\' + '*.json')\n",
    "        downloaded_list = [int(os.path.splitext(x.split('\\\\')[-1])[0]) for x in all_files]\n",
    "\n",
    "        # 首頁連線\n",
    "        home_page_html = self.crawler.get_html('https://rent.591.com.tw/')\n",
    "        if home_page_html.status_code != requests.codes.ok:\n",
    "            self.logger.warning('https://rent.591.com.tw/ 連線失敗')\n",
    "            raise Exception\n",
    "\n",
    "        # 取得 csrf-token\n",
    "        soup = BeautifulSoup(home_page_html.text, \"lxml\")\n",
    "        token_element = soup.find('meta', {'name': 'csrf-token'})\n",
    "        csrf_token = token_element['content']\n",
    "\n",
    "        # 獲取資料總數\n",
    "        self.crawler.add_header('X-CSRF-TOKEN', csrf_token)\n",
    "        list_pages_html = self.crawler.get_html('https://rent.591.com.tw/home/search/rsList?kind=0&region=8')\n",
    "        if list_pages_html.status_code != requests.codes.ok:\n",
    "            self.logger.warning('https://rent.591.com.tw/home/search/rsList?kind=0&region=8 連線失敗')\n",
    "            raise Exception\n",
    "        total_records_num = int(re.sub(',', '', json.loads(list_pages_html.text)['records']))\n",
    "\n",
    "        self.logger.info('搜尋總數 {0} 筆資料'.format(total_records_num))\n",
    "\n",
    "        # 抓個別頁面時 header 需要多 2 個參數\n",
    "        t591 = home_page_html.cookies.get_dict()['T591_TOKEN']\n",
    "        self.crawler.add_header('deviceid', t591)\n",
    "        self.crawler.add_header('device', 'pc')\n",
    "        \n",
    "        # 逐頁取得個別 post_id\n",
    "        # 並存檔\n",
    "        current_page_num = 0\n",
    "        while True:\n",
    "            url = 'https://rent.591.com.tw/home/search/rsList?kind=0&region=8&firstRow={0}'.format(current_page_num*30)\n",
    "\n",
    "            self.logger.info('執行第 {0} 頁, url: {1}'.format(current_page_num, url))\n",
    "\n",
    "            current_page_html = self.crawler.get_html(url)\n",
    "            self.crawler.sleep_random_secends()\n",
    "            if current_page_html.status_code != requests.codes.ok:\n",
    "                self.logger.warning('{0} 連線失敗'.format(url))\n",
    "                raise Exception\n",
    "            current_page = json.loads(current_page_html.text)\n",
    "            post_ids = [x['post_id'] for x in current_page['data']['data']]\n",
    "\n",
    "            if not post_ids:\n",
    "                self.logger.info('下載結束!')\n",
    "                break\n",
    "\n",
    "            # 取得個別租案資料並存檔\n",
    "            for post_id in post_ids:\n",
    "                if post_id in downloaded_list:\n",
    "                    self.logger.info('{0} 已經存在~將跳過!'.format(post_id))\n",
    "                    continue\n",
    "                \n",
    "                house_url = 'https://bff.591.com.tw/v1/house/rent/detail?id={0}'.format(post_id)\n",
    "                self.logger.debug('執行url: {0}'.format(house_url))\n",
    "                house_html = self.crawler.get_html(house_url)\n",
    "                if house_html.status_code != requests.codes.ok:\n",
    "                    self.logger.warning('{0} 連線失敗'.format(house_url))\n",
    "                    continue\n",
    "                \n",
    "                house_content = json.loads(house_html.text)\n",
    "                with open(save_dir + '\\\\' + '{0}.json'.format(post_id), 'w', encoding='utf8') as f:\n",
    "                    json.dump(house_content, f, indent=4,ensure_ascii=False)\n",
    "                self.crawler.sleep_random_secends()\n",
    "\n",
    "            current_page_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawler591 = Crawler591()\n",
    "crawler591.get_details(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
